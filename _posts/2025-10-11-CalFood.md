---
layout: post
title: "CalFood: Hybrid Food Calorie Estimation System Using YOLOv8-Segmentation & Multivariate Polynomial Regression"
date: 2025-10-11
author: "Fara Rahmasari Fahirun"
categories: [Computer Vision, Machine Learning, Deep Learning]
tags: [Python, PyTorch, YOLOv8, Instance Segmentation, Multivariate Regression, OpenCV, Scikit-learn]
image: /assets/img/calfood.png
---

## **Project Description**

CalFood is my individual research-driven computer vision project designed to address the real-world challenge of accurate and practical dietary assessment. Traditional methods like manual food logging are burdensome and often biased, while existing automated solutions typically require impractical hardware like depth sensors or complex multi-view camera setups.

In this project, I developed a practical, hybrid system for automated food calorie estimation using only **single-view, top-down images**. My primary objective was to balance high accuracy with user convenience for potential mobile application scenarios. I synergized state-of-the-art deep learning for visual perception with classical statistical modeling for mass estimation.

The core innovation I implemented lies in combining a **YOLOv8-Segmentation** model for precise real-time object detection and instance segmentation with a **Multivariate Polynomial Regression** model. Instead of relying on overly simplified geometric assumptions (e.g., assuming all food is cylindrical), I trained regression models to learn the complex mapping between five distinct 2D geometric features (real area, perimeter, width, height, and aspect ratio) extracted from the segmentation mask directly to 3D mass. Crucially, I achieved objective spatial calibration by using a standardized reference coin in the image, eliminating the variability problems of using biological proxies like thumbs.

## **My Role & Contribution**

As the sole researcher and developer for CalFood, I was responsible for the entire project lifecycle:

* **Research & Methodology Design:** I formulated the hybrid approach combining instance segmentation with multivariate regression and designed the objective coin-based calibration method.
* **Data Preparation:** I curated, cleaned, and preprocessed two distinct datasets for separate training tasks: a custom Roboflow dataset for segmentation and the ECUSTFD dataset for regression training with mass annotations.
* **Model Development:** I implemented and fine-tuned the YOLOv8s-seg model using PyTorch and Ultralytics. I developed the automated feature extraction pipeline from scratch using OpenCV and NumPy. I also designed and trained category-specific Multivariate Polynomial Regression models using Scikit-learn.
* **System Integration & Testing:** I built the complete end-to-end inferencing pipeline and conducted rigorous quantitative evaluation using industry-standard metrics (mAP, MAPE, R-squared) as well as practical demo trials to validate real-world performance.
* **Analysis & Documentation:** I authored the comprehensive IEEE-style research paper detailing the methodology, experimental results, and providing a critical analysis of limitations such as data dependency.

## **Methodology**

### **Datasets**
To ensure rigorous training and evaluation, I employed two distinct, purpose-built datasets utilizing top-down perspectives:
* **Dataset A (Segmentation Training):** A custom dataset from Roboflow containing **20 distinct classes** (19 diverse food categories + 1 reference coin category) with high-quality, manually annotated polygon masks. I used this exclusively to train and validate the YOLOv8s-seg model's visual perception.
* **Dataset B (Regression Training & Testing):** A subset derived from the **ECUSTFD dataset**, comprising food images accompanied by precise ground truth mass measurements (in grams). I used a total of **171 validated samples** spanning various food categories to train and evaluate the category-specific regression models.

### **System Workflow**
The CalFood system I developed operates through a sequential six-stage pipeline:
1.  **Data Acquisition:** Capture a single top-down RGB image of food items alongside a standardized reference coin.
2.  **Instance Segmentation (YOLOv8):** The YOLOv8s-seg model detects objects and generates binary masks for food items and the coin.
3.  **Spatial Calibration:** The system calculates the pixel area of the coin mask. Based on the known physical area of the coin, a global pixel-to-metric scale factor (cmÂ²/pixel) is derived.
4.  **Geometric Feature Extraction:** Five morphological features are extracted from each food mask and converted to metric units: Real Area, Real Perimeter, Real Width, Real Height, and Aspect Ratio.
5.  **Mass Estimation (Regression):** The extracted feature vector serves as input to a pre-trained, category-specific Multivariate Polynomial Regression model to predict mass in grams.
6.  **Calorie Computation:** Final calorie content is derived by multiplying the estimated mass by the food's specific caloric density factor (kcal/g).

### **Architecture Components**
* **Visual Perception:** I selected **YOLOv8-Segmentation (yolov8s-seg)** for its optimal balance of real-time inference speed and high segmentation accuracy (achieving an mAP50-95 of 0.665 on the validation set).
* **Mass Estimation:** I chose **Multivariate Polynomial Regression (Degree 2)** to model non-linear relationships between 2D planar features and 3D mass, offering greater flexibility than rigid geometric primitives.

## **Results and Discussion**

My extensive experiments on the test dataset demonstrated strong overall system performance. The hybrid approach achieved a **Mean Absolute Percentage Error (MAPE) of 5.36%**, which corresponds to a **system accuracy of 94.64%**.

I also conducted an end-to-end demo trial on an unseen image of an apple, which successfully estimated the mass with high precision (Estimated: 152.30g vs. Actual: ~150g) and computed the calories as 79.20 kcal.

| Evaluation Parameter | Result |
| :--- | :--- |
| Total Test Samples | 167 |
| Mean Absolute Error (MAE) | 8.45 g |
| **Mean Absolute Percentage Error (MAPE)** | **5.36%** |
| Overall System Accuracy | 94.64% |

**Key Analysis:**
My critical analysis revealed a severe dependency on training data density. Categories with sufficient training samples and relatively uniform shapes (e.g., Sachima, Tomato) achieved near-perfect estimation, with R-squared scores approaching 1.0 and MAPE near 0%. However, data-scarce categories like Apple (n=2 samples) and Banana (n=1 sample) exhibited significant overfitting and high errors (MAPE up to 63.93%). Irregular foods with unobservable thickness variations (e.g., Mango) also showed higher errors. This underscores that while the hybrid methodology is sound and effective, its robust real-world generalization is contingent upon the availability of substantial, diverse datasets with ground truth mass.

## **Frameworks & Tools Used**

* **Language:** Python 3.9.13
* **Deep Learning:** PyTorch 1.13.1 (with CUDA 11.7), Ultralytics YOLOv8
* **Machine Learning:** Scikit-learn 1.2.2
* **Computer Vision & Data Processing:** OpenCV 4.7.0, NumPy, Pandas, Pillow
* **Hardware:** Workstation with Intel Core i7-10700K, 32GB RAM, NVIDIA GeForce RTX 3060 (12GB VRAM).

## **Project Links**

* **Research Paper:** [Download PDF](https://drive.google.com/file/d/1Wg4_eU82VmxmOm5q-Y_VBuFMxc_S5OjP/view?usp=sharing)
* **Source Code Repository:** [GitHub](https://github.com/farafahirun/CalFood.git)

## **Future Work & Development Plans**

This research serves as a foundational step towards a practical, user-centric dietary assessment tool. The immediate future development plans are focused on transitioning the current research prototype into a deployable application:

1.  **Mobile Application Development:** The primary goal is to develop a cross-platform mobile application (iOS/Android) using frameworks like Flutter or React Native. This will bring the single-view calorie estimation capability directly to end-users' smartphones.
2.  **Backend API Deployment:** The core Python-based inference pipeline (YOLOv8 + Regression models) will be deployed as a scalable RESTful API (e.g., using FastAPI or Flask) on a cloud server. The mobile app will communicate with this backend for image processing and calorie computation.
3.  **User Interface (UI/UX) Design:** Designing an intuitive and user-friendly interface that guides users through the process of capturing top-down food images with a reference coin and presents nutritional information clearly.
4.  **Database Expansion:** To address the data dependency limitation identified in the research, a continuous data collection effort will be integrated into the application to gather more diverse food images and ground truth mass data, further improving model robustness over time.

## **Conclusion**

CalFood successfully validates a practical hybrid framework for automated single-view food calorie estimation. By synergizing deep learning-based segmentation with classical multivariate regression and objective coin-based calibration, the system achieves high accuracy (94.64%) without specialized hardware. It offers a viable, scalable foundation for next-generation mobile dietary assessment tools, provided that the critical challenge of data availability for regression training is addressed.